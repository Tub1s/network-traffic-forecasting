{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src', 'features')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility imports\n",
    "import pickle\n",
    "from preprocessing import get_list_of_datapaths, load_data, make_train_test_datasets, split_sequence\n",
    "from metrics import calculate_metrics\n",
    "\n",
    "# Math and matrix manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graphing imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning imports\n",
    "import tensorflow as tf\n",
    "import river\n",
    "from river import ensemble\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import optim\n",
    "from river import preprocessing\n",
    "from river import tree\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), 'Physical GPUs,', len(logical_gpus), 'Logical GPUs')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../datasets/traffic/\"\n",
    "RESULTS_PATH = \"../results\"\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(os.join(RESULTS_PATH, \"classical\"), exist_ok=True)\n",
    "\n",
    "list_of_datafiles = get_list_of_datapaths(DATA_PATH, sort = True)\n",
    "df = load_data(list_of_datafiles)\n",
    "train_df, test_df = make_train_test_datasets(df, split_point=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(15,7))\n",
    "sns.boxplot(data=train_df, ax=axs[0])\n",
    "sns.boxplot(data=test_df, ax=axs[1])\n",
    "axs[0].set_title('Train dataset')\n",
    "axs[1].set_title('Test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(target: str):\n",
    "    fig, axs = plt.subplots(ncols=1, nrows=3, figsize=(22,10))\n",
    "    fig.tight_layout()\n",
    "    sns.lineplot(data=train_df, x=np.arange(0, train_df.shape[0], 1), y=target, ax=axs[0]).set_title(f\"Train dataset visualization {target}\")\n",
    "    for ax in axs:\n",
    "        ax.set(ylabel=\"Transfer value in node\")\n",
    "    sns.lineplot(data=test_df, x=np.arange(0, test_df.shape[0], 1), y=target, ax=axs[1]).set_title(f\"Test dataset visualization {target}\")\n",
    "    sns.lineplot(data=df, x=np.arange(0, df.shape[0], 1), y=target, ax=axs[2]).set_title(f\"Full dataset visualization {target}\")\n",
    "    plt.savefig(f\"plot_{target.replace('>', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('5->8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('8->5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('5->12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('8->12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_online_experiment(df, n_input_size, n_output_size, target, model_type):\n",
    "    X_online, y_online = split_sequence(sequence = df[target], n_input_steps=n_input_size, n_output_steps=n_output_size)\n",
    "    X_online = X_online.reshape((X_online.shape[0], X_online.shape[1]))\n",
    "\n",
    "\n",
    "    if model_type == \"default\":\n",
    "        \n",
    "        online_model = river.compose.Pipeline(\n",
    "        river.preprocessing.StandardScaler(),\n",
    "        river.linear_model.LinearRegression(river.optim.SGD(lr=0.3))\n",
    "        )\n",
    "\n",
    "        online_metric = river.metrics.SMAPE()\n",
    "\n",
    "        online_predicted = list()\n",
    "        for xi, yi in river.stream.iter_array(X_online, y_online):\n",
    "            yi_pred = online_model.predict_one(xi)\n",
    "\n",
    "            online_metric.update(yi[0], yi_pred)\n",
    "            online_predicted.append(yi_pred)\n",
    "            #print(f\"g-t {yi[0]} | pred {yi_pred}\")\n",
    "\n",
    "            online_model.learn_one(xi, yi[0])\n",
    "\n",
    "        data = {\n",
    "            \"y_real\": y_online,\n",
    "            \"y_pred\": online_predicted,\n",
    "            \"metric\": online_metric\n",
    "        }\n",
    "    \n",
    "\n",
    "    elif model_type == \"bagging_regressor\":\n",
    "        br_metric = metrics.SMAPE()\n",
    "        br_model = preprocessing.StandardScaler()\n",
    "        br_model |= ensemble.BaggingRegressor(\n",
    "            model=linear_model.LinearRegression(intercept_lr=0.3),\n",
    "            n_models=5,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        br_predicted = list()\n",
    "        for xi, yi in river.stream.iter_array(X_online, y_online):\n",
    "            yi_pred = br_model.predict_one(xi)\n",
    "\n",
    "            br_metric.update(yi[0], yi_pred)\n",
    "            br_predicted.append(yi_pred)\n",
    "            #print(f\"g-t {yi[0]} | pred {yi_pred}\")\n",
    "\n",
    "            br_model.learn_one(xi, yi[0])\n",
    "        \n",
    "        data = {\n",
    "            \"y_real\": y_online,\n",
    "            \"y_pred\": br_predicted,\n",
    "            \"metric\": br_metric\n",
    "        }\n",
    "\n",
    "\n",
    "    else:\n",
    "        online_models_greedy = [\n",
    "            river.linear_model.LinearRegression(optimizer=river.optim.SGD(lr=lr))\n",
    "            for lr in [0.0001, 0.001, 1e-05, 0.01]\n",
    "        ]\n",
    "\n",
    "        online_model_greedy = (\n",
    "        river.preprocessing.StandardScaler() |\n",
    "            river.model_selection.EpsilonGreedyRegressor(\n",
    "            online_models_greedy,\n",
    "            epsilon=0.1,\n",
    "            decay=0.001,\n",
    "            burn_in=100,\n",
    "            seed=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        online_metric_greedy = river.metrics.SMAPE()\n",
    "\n",
    "        online_predicted_greedy = list()\n",
    "        for xi, yi in river.stream.iter_array(X_online, y_online):\n",
    "            yi_pred = online_model_greedy.predict_one(xi)\n",
    "\n",
    "            online_metric_greedy.update(yi[0], yi_pred)\n",
    "            online_predicted_greedy.append(yi_pred)\n",
    "            #print(f\"g-t {yi[0]} | pred {yi_pred}\")\n",
    "            \n",
    "            online_model_greedy.learn_one(xi, yi[0])\n",
    "\n",
    "        data = {\n",
    "            \"y_real\": y_online,\n",
    "            \"y_pred\": online_predicted_greedy,\n",
    "            \"metric\": online_metric_greedy\n",
    "        }\n",
    "\n",
    "    with open(RESULTS_PATH + f\"classical/online_{model_type}_in{n_input_size}_out{n_output_size}_t{target.replace('->', '-')}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = [\"5->8\", \"8->5\", \"5->12\", \"8->12\"]\n",
    "in_sizes = [1, 2, 5, 10, 25, 50, 100]\n",
    "exp_models = [\"greedy\", \"random_forest_regressor\"]\n",
    "\n",
    "for model in exp_models:\n",
    "    for target in df_targets:\n",
    "        for in_size in in_sizes:\n",
    "            run_online_experiment(df, in_size, 1, target, model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d3e74f3df94fb62d833199ff807b97996d62fb18dca42b5a455cf9687e2e8c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
