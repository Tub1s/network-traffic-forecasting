{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Dane 30tyś iteracji\n",
    "#* Wystapienie awarii po 20tyś iteracji\n",
    "    \n",
    "#* Wen, Qingsong, et al. \"Transformers in Time Series: A Survey.\" arXiv preprint arXiv:2202.07125 (2022).\n",
    "#* https://arxiv.org/pdf/2202.07125.pdf\n",
    "\n",
    "#* Online Machine Learning\n",
    "#* https://analyticsindiamag.com/how-to-learn-from-streaming-data-with-creme-in-python/\n",
    "\n",
    "#* Timeseries Forecasting\n",
    "#* https://www.tensorflow.org/tutorials/structured_data/time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14002ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* Czy każdy model powinien być wyuczony dla jednego połączenia\n",
    "\n",
    "#* Czy w ramach predykcji powinniśmy analizować działanie także model zaczyna predykcje od N ostatnich próbek\n",
    "\n",
    "#* Następnie w każdym kolejnym kroku wykorzystuje poprzednie N-1 próbek oraz ostatnio przewidzianą próbkę\n",
    "#* W ten sposób po N krokach każda kolejna predykcja będzie wykonywana na podstawie jedynie przewidzianych próbek\n",
    "#* Bez udziału próbek realnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility imports\n",
    "import os\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Math and matrix manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graphing imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow required\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), 'Physical GPUs,', len(logical_gpus), 'Logical GPUs')\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./datasets/traffic/\"\n",
    "# Lista pozwalajaca zobaczyc skladowe generowanego sygnalu\n",
    "list_of_datafiles = os.listdir(DATA_PATH)\n",
    "list_of_datafiles = sorted([int(x.replace('.txt', '')) for x in list_of_datafiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list_of_datafiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(list)\n",
    "\n",
    "# TODO: Zmienic w funkcje\n",
    "# TODO: Dodac multiprocessing\n",
    "for file in tqdm.tqdm(list_of_datafiles):\n",
    "    temp = np.loadtxt(f\"{DATA_PATH}{str(file)}.txt\")\n",
    "    #temp = np.loadtxt(f\"{DATA_PATH}{file}\")\n",
    "    df['5->8'].append(temp[5][8])\n",
    "    df['8->5'].append(temp[8][5])\n",
    "    df['5->12'].append(temp[5][12])\n",
    "    df['8->12'].append(temp[8][12])\n",
    "\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(df)\n",
    "train_df = df[:20000]\n",
    "test_df = df[20000:].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(15,7))\n",
    "sns.boxplot(data=train_df, ax=axs[0])\n",
    "sns.boxplot(data=test_df, ax=axs[1])\n",
    "axs[0].set_title('Train dataset')\n",
    "axs[1].set_title('Test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(target: str):\n",
    "    fig, axs = plt.subplots(ncols=1, nrows=3, figsize=(30,7))\n",
    "    sns.lineplot(data=train_df, x=np.arange(0, train_df.shape[0], 1), y=target, ax=axs[0]).set_title(f\"Wizualizacja zbioru treningowego {target}\")\n",
    "    sns.lineplot(data=test_df, x=np.arange(0, test_df.shape[0], 1), y=target, ax=axs[1]).set_title(f\"Wizualizacja zbioru testowego {target}\")\n",
    "    sns.lineplot(data=df, x=np.arange(0, df.shape[0], 1), y=target, ax=axs[2]).set_title(f\"Wizualizacja całego zbioru {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('5->8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('8->5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('5->12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data('8->12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(*, sequence, n_input_steps=5, n_output_steps=1):\n",
    "    X, y = list(), list()\n",
    "    for i in range(sequence.shape[0]):\n",
    "        if i + n_input_steps + n_output_steps < len(sequence) + 1:\n",
    "            seq_x, seq_y = list(sequence[i:i+n_input_steps]), list(sequence[i+n_input_steps:i+n_input_steps+n_output_steps])\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_steps = 1\n",
    "n_output_steps = 1\n",
    "#target = '5->8'\n",
    "#target = '8->5'\n",
    "target = '5->12'\n",
    "#target = '8->12'\n",
    "X_train, y_train = split_sequence(sequence = train_df[target], n_input_steps=n_input_steps, n_output_steps=n_output_steps)\n",
    "X_test, y_test = split_sequence(sequence = test_df[target], n_input_steps=n_input_steps, n_output_steps=n_output_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063725a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Zmodyfikować tworzenie zbioru w taki sposób, aby funkcja train_model sama wybierała poprawny cel tj. '5->8', '8->5' itd.\n",
    "def build_model(n_input_steps: int, n_output_steps: int, n_features: int, *, model_type: str) -> tf.keras.Model:\n",
    "    model_types = ['LSTM']\n",
    "    if model_type in model_types:\n",
    "        if model_type == 'LSTM':\n",
    "            model = keras.Sequential()\n",
    "            model.add(layers.LSTM(50, activation='relu', input_shape=(n_input_steps, n_features)))\n",
    "            model.add(layers.Dense(n_output_steps))\n",
    "            model.compile(optimizer='adam', loss='mse')\n",
    "    else:\n",
    "        print('Model niedostępny')\n",
    "        return\n",
    "    \n",
    "    return model\n",
    "\n",
    "# TODO: Dodać podział na zbiór walidacyjny i testowy?\n",
    "def train_model(input_data: np.array, input_target: str, output_data: np.array, output_target: str, \n",
    "                model_type: str, epochs: int = 20, verbose: int = 1, early_stopping: bool = True) -> str:\n",
    "    n_input_steps = input_data.shape[1]\n",
    "    n_output_steps = output_data.shape[1]\n",
    "    n_features = input_data.shape[2]\n",
    "\n",
    "    models_path = './saved_models/'\n",
    "\n",
    "    if not os.path.exists(models_path):\n",
    "        os.mkdir(models_path)\n",
    "\n",
    "    saved_models = os.listdir(models_path)\n",
    "    model_name = f'{model_type}_{input_target}to{output_target}_in{str(n_input_steps)}_out{str(n_output_steps)}'\n",
    "    model_path = f'{models_path}{model_name}'\n",
    "    target = f'{input_target}->{output_target}'\n",
    "\n",
    "    if model_name not in saved_models:\n",
    "        es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=3)\n",
    "        model = build_model(n_input_steps=n_input_steps, n_output_steps=n_output_steps, n_features=n_features, \n",
    "                            model_type=model_type)\n",
    "        model.fit(input_data, output_data, epochs=20, verbose=1, callbacks=[es])\n",
    "        model.save(model_path)\n",
    "        del model\n",
    "\n",
    "        print('Zakończono trening i zapis modelu ')\n",
    "        print(f'Wczytano ścieżkę modelu: {model_path}\\n')\n",
    "\n",
    "    else:\n",
    "        print(f'Model {model_name} już istnieje')\n",
    "        print(f'Wczytano ścieżkę modelu: {model_path}')\n",
    "        print('W celu wytrenowania nowego modelu należy ręcznie usunąć zapisane pliki\\n')\n",
    "\n",
    "    return model_path\n",
    "\n",
    "def test_model(input_data: np.array, output_data: np.array, model_path: str = None, model_type: str = None):\n",
    "    if model_path is None and model_type is None:\n",
    "        print('Nie wybrano żadnego modelu')\n",
    "        print('Podaj ścieżkę do modelu lub wybierz typ modelu')\n",
    "        return\n",
    "    elif model_path is not None and model_type is not None:\n",
    "        print('Wybrano zbyt wiele modeli')\n",
    "        print('Podaj ścieżkę do modelu lub wybierz typ modelu')\n",
    "        return\n",
    "\n",
    "    elif model_path is not None and model_type is None:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        y_pred = model.predict(input_data, verbose=0)\n",
    "\n",
    "    elif model_path is None and model_type is not None:\n",
    "        return\n",
    "    \n",
    "\n",
    "    print(f'MAPE: {smape(output_data, y_pred)}')\n",
    "    for i in range(len(output_data)):\n",
    "        print(f\"real: {output_data[i]} | pred: {y_pred[i]}\")\n",
    "\n",
    "    figure = plt.figure(figsize = (20, 15))\n",
    "    ax = plt.subplot(111)\n",
    "    line = ax.plot(np.arange(0, output_data.shape[0], 1), output_data, 'r', linewidth=5)\n",
    "    line2 = ax.plot(np.arange(0, y_pred.shape[0], 1), y_pred, 'b', linewidth=1)\n",
    "\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "              fancybox=True, shadow=True, ncol=2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def smape(A, F):\n",
    "    tmp = 2 * np.abs(F - A) / (np.abs(A) + np.abs(F))\n",
    "    len_ = np.count_nonzero(~np.isnan(tmp))\n",
    "    if len_ == 0 and np.nansum(tmp) == 0: # Deals with a special case\n",
    "        return 100\n",
    "    return 100 / len_ * np.nansum(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = train_model(input_data=X_train, input_target=5, output_data=y_train, output_target=12, model_type='LSTM')\n",
    "test_model(input_data=X_test, output_data=y_test, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d57594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train.reshape((X_train.shape[0], X_train.shape[1])), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7208a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test.reshape((X_test.shape[0], X_test.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MAPE: {smape(y_test, y_pred):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(f\"real: {y_test[i]} | pred: {y_pred[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "#from functools import partial\n",
    "\n",
    "#new_dict = defaultdict(lambda: numpy.zeros(array_size))\n",
    "#defaultdict(partial(numpy.ndarray, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4314c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "list_of_int = [1, 2, 3]\n",
    "list_of_str = ['1', '2', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f94e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe081cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typeguard import check_type\n",
    "\n",
    "try:\n",
    "    check_type('list_of_int', list_of_int, List[int])\n",
    "    print(\"string_list conforms to string_list_class\")\n",
    "except TypeError:\n",
    "    print(\"string_list does not conform to string_list_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_type('list_of_int', list_of_int, List[int])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1be7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7cfe90efdc2fcbbc362c1f6ecb7538b200d00187f10032c348f27b58166711f8"
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
